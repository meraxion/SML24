{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. **Restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "3. __Use the__ `Validate` __button in the Assignments tab before submitting__.\n",
    "\n",
    "__Include comments, derivations, explanations, graphs, etc.__ \n",
    "\n",
    "You __work in groups__ (= 3 people). __Write the full name and S/U-number of all team members!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "* Student 1 Stian GrÃ¸nlund, s1122151:\n",
    "* Student 2 name, S/U-number:\n",
    "* Student 3 name, S/U-number:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d20379170bc51875042ec1b31bfd4ab3",
     "grade": false,
     "grade_id": "cell-4a3707609a8bbfee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Assignment 1 (Statistical Machine Learning 2024)\n",
    "# **Deadline: 27 September 2024**\n",
    "\n",
    "## Instructions\n",
    "* Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE` __including comments, derivations, explanations, graphs, etc.__ \n",
    "Elements and/or intermediate steps required to derive the answer have to be in the report. If an exercise requires coding, explain briefly what the code does (in comments). All figures should have titles (descriptions), axis labels, and legends.\n",
    "* Please do __not add new cells__ to the notebook, try to write the answers only in the provided cells. Before you turn the assignment in, make sure everything runs as expected.\n",
    "* __Use the variable names given in the exercises__, do not assign your own variable names. \n",
    "* __Only one team member needs to upload the solutions__. This can be done under the Assignments tab, where you fetched the assignments, and where you can also validate your submissions. Please do not change the filenames of the individual Jupyter notebooks.\n",
    "\n",
    "For any problems or questions regarding the assignments, ask during the tutorial or send an email to charlotte.cambiervannooten@ru.nl and janneke.verbeek@ru.nl .\n",
    "\n",
    "## Introduction\n",
    "Assignment 1 consists of:\n",
    "1. Polynomial curve fitting (50 points);\n",
    "2. __Gradient descent (25 points);__\n",
    "3. Fruit boxes (25 points);\n",
    "4. Probability factorization (BONUS 10 points);\n",
    "\n",
    "## Libraries\n",
    "\n",
    "Please __avoid installing new packages__, unless really necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0bbce81100157570e2530b5ac3d1fbd",
     "grade": false,
     "grade_id": "cell-3b986e21540420a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it to at least version 3.\"\n",
    "\n",
    "# Necessary imports (for solutions)\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "\n",
    "# Set fixed random seed for reproducibility\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7657b108c988a0a885b75370a706a398",
     "grade": false,
     "grade_id": "cell-836d26d54fcf8d85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Gradient descent (weight 25)\n",
    "In this exercise, we consider the gradient descent algorithm for function minimization. When the function to be minimized is $E(\\mathbf{x})$, the gradient descent iteration is  \n",
    "\\begin{equation*}\n",
    "\\mathbf{x}_{n+1} = \\mathbf{x}_n - \\eta \\nabla E(\\mathbf{x}_n) \\tag{6}\n",
    "\\end{equation*}\n",
    "where $\\eta>0$ is the so-called learning-rate. In the following, we will apply gradient descent to the function\n",
    "\\begin{equation*}\n",
    "h(x,y) = 100(y - x^2)^2 +(1 - x)^2 \\label{banana} \\tag{7}\n",
    "\\end{equation*}\n",
    "### Exercise 2.1\n",
    "Make a plot of the function $h$ over the interval $[-2 \\leq x \\leq 2] \\times [-1 \\leq y \\leq 3]$. (Tip: Use the `plot_surface` function.) Can you guess from the plot if numerical minimization with gradient descent will be fast or slow for this function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "124d3a011b106eb7b5a2fc12fc7c8252",
     "grade": true,
     "grade_id": "cell-5dfbbae25832f037",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "371c859e41a03de5c22ae0fc724183ae",
     "grade": false,
     "grade_id": "cell-d2b407ddc3fbb9fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create function h.\n",
    "\"\"\"\n",
    "def h(x,y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\"\"\"\n",
    "Declare x and y.\n",
    "\"\"\"    \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58de08700db19e1a51b8e953327d4e6b",
     "grade": true,
     "grade_id": "cell-e9cba008bca6b37a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hidden test for function h.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2239ad6ded3020c37b621c88c32e1681",
     "grade": true,
     "grade_id": "cell-85ead8c8bd53e79c",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a function to plot h.\n",
    "\"\"\"\n",
    "def plot_h(x,y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "plot_h(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4bb88056c5626a0a29bb4c6b368cdc3c",
     "grade": false,
     "grade_id": "cell-31bd1472cf7b6923",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.2\n",
    "Knowing that a critical point of a function is a point where the gradient vanishes, show that $(1, 1)$ is the unique critical point of $h$.  Prove that this point is a minimum for $h$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8618eff65f48f8ec036124d062b75a85",
     "grade": true,
     "grade_id": "cell-1336cb1e9d7d38bd",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f364c5d37276985a059a4c79d34bf3a8",
     "grade": false,
     "grade_id": "cell-8f880d3ed9688c1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.3\n",
    "Write down the gradient descent iteration rule for function $h$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e7efecd79cbb1883af94d8037de177c",
     "grade": true,
     "grade_id": "cell-91163736650b6698",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9814f7d9859af71756f720cd7b349d7",
     "grade": false,
     "grade_id": "cell-55ab98d23c58aa29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.4\n",
    "Implement gradient descent. Try some different values of $\\eta$. Does the algorithm converge? How fast? Make plots of the trajectories on top of a contour plot of $h$. (Hint: have a look at the example contour_example.py on Brightspace for inspiration to plot contours of functions and trajectories). Report your findings. Explain why numerical minimization with gradient descent is slow for this function.\n",
    "\n",
    "First implement the derivative of $h(x,y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61078eb4e5d6d36456e47eef815c91bb",
     "grade": false,
     "grade_id": "cell-ebfab8f71f837375",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dh_dxy(x, y):\n",
    "    \"\"\"\n",
    "    This function is the derivative of the function h(x, y).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        data point from x-axis\n",
    "    y : float\n",
    "        data point from y-axis\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    vals : array\n",
    "        NumPy array of parameter values computed during minimization\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ebd63a15d17d5c9c196dcafa639bbda",
     "grade": true,
     "grade_id": "cell-14c1d4dd062d9e68",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test for dh_dxy.\n",
    "\"\"\"\n",
    "assert np.array_equal(dh_dxy(1, 1), np.array([0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d476333c67e846816f1803ecfa82dd1",
     "grade": false,
     "grade_id": "cell-f8b8e6054e370fc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now implement the gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd01bbc0f934f977012cf562398b2fc0",
     "grade": false,
     "grade_id": "cell-e5e7a55f7e7d740f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def grad_descent(grad, val_init, eta, max_iter, tol):\n",
    "    \"\"\" This function implements the gradient descent algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    grad : function\n",
    "        Returns the derivative of the function with respect to the pair (x, y).\n",
    "    val_init : tuple\n",
    "        Initial values for parameters\n",
    "    eta : float\n",
    "        Gradient descent learning rate\n",
    "    max_iter : int\n",
    "        Maximum number of gradient descent iterations\n",
    "    tol : float\n",
    "        Tolerance for detecting convergence\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    vals : array\n",
    "        NumPy array of parameter values computed during minimization\n",
    "    dists : array\n",
    "        NumPy array of distances from the current point to the previous point\n",
    "    tot_iter : int\n",
    "        Number of performed gradient descent iterations\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6b956a195e4bca05d7de1b84561f6ae",
     "grade": true,
     "grade_id": "cell-9cce6b818f4aa52e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hidden test for grad_descent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9236de9eb8bc43a4cf517390f9a9eb46",
     "grade": false,
     "grade_id": "cell-2829e4b5e8af0502",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, run the gradient descent algorithm with different values of $\\eta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fff6722c457109e005a5829f5226dca6",
     "grade": true,
     "grade_id": "cell-76876feddeb4a5f0",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7634321ff4885a6d2755269999ee081a",
     "grade": false,
     "grade_id": "cell-87fcba196081149d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Explain what you see!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6dbdf1d1e4690f075aaa40f9de04f02",
     "grade": true,
     "grade_id": "cell-40c451de6dac1163",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
