{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. **Restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "3. __Use the__ `Validate` __button in the Assignments tab before submitting__.\n",
    "\n",
    "__Include comments, derivations, explanations, graphs, etc.__ \n",
    "\n",
    "You __work in groups__ (= 3 people). __Write the full name and S/U-number of all team members!__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "GROUP NUMBER (brightspace): 13\n",
    "* Andrew Schroeder, s1111686\n",
    "* Stian GrÃ¸nlund,   s1122151\n",
    "* Monika Kazlauskaite, s1126411"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "455930b85ab14a590f9976170c4894ea",
     "grade": false,
     "grade_id": "cell-e3a6a6b02afe0d83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3 (Statistical Machine Learning 2024)\n",
    "# **Deadline: 22 November 2024**\n",
    "\n",
    "## Instructions\n",
    "* Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE` __including comments, derivations, explanations, graphs, etc.__ \n",
    "Elements and/or intermediate steps required to derive the answer have to be in the report. If an exercise requires coding, explain briefly what the code does (in comments). All figures should have titles (descriptions), axis labels, and legends.\n",
    "* __Please use LaTeX to write down equations/derivations/other math__! How to do that in Markdown cells can be found [here](https://www.fabriziomusacchio.com/blog/2021-08-10-How_to_use_LaTeX_in_Markdown/), a starting point for various symbols is [here](https://www.overleaf.com/learn/latex/Mathematical_expressions).\n",
    "* Please do __not add new cells__ to the notebook, try to write the answers only in the provided cells. Before you turn the assignment in, make sure everything runs as expected.\n",
    "* __Use the variable names given in the exercises__, do not assign your own variable names. \n",
    "* __Only one team member needs to upload the solutions__. This can be done under the Assignments tab, where you fetched the assignments, and where you can also validate your submissions. Please do not change the filenames of the individual Jupyter notebooks.\n",
    "\n",
    "For any problems or questions regarding the assignments, ask during the tutorial or send an email to charlotte.cambiervannooten@ru.nl and janneke.verbeek@ru.nl .\n",
    "\n",
    "## Introduction\n",
    "Assignment 3 consists of:\n",
    "1. The faulty lighthouse (30 points);\n",
    "2. Gaussian processes (40 points);\n",
    "3. __Bayesian polynomial regression (30 points)__.\n",
    "\n",
    "## Libraries\n",
    "\n",
    "Please __avoid installing new packages__, unless really necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7c1d5b4e883df09233e627b7e5cab66",
     "grade": false,
     "grade_id": "cell-57d156d70e92c9aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set fixed random seed for reproducibility\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d49d9f5237d77de3f03fd1497a6caf2",
     "grade": false,
     "grade_id": "cell-bbbb25e0adf08276",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Bayesian polynomial regression (30 points)\n",
    "In this exercise, we will consider the _Bayesian_ treatment of polynomial regression. Recall polynomial regression \n",
    "\\begin{equation}\n",
    "t_{n} = \\omega_{0} + \\omega_{1}x_{n} + \\omega_{2} x_{x}^{2}+\\dots+\\omega_{M}x_{n}^{M}+\\epsilon_{n}, \n",
    "\\end{equation}\n",
    "where $\\epsilon_{n}\\sim N(0, \\sigma^{2})$. In the vector form we have \n",
    "\\begin{equation}\n",
    "t_{n} = \\boldsymbol{\\omega}^{T}\\boldsymbol{x}_{n}+\\epsilon_{n}, \n",
    "\\end{equation}\n",
    "where $\\boldsymbol{\\omega}=[\\omega_{0}, \\dots, \\omega_{M}]^{T}$ and $\\boldsymbol{x}_{n}=[1,x_{n}, x_{n}^{2}, \\dots, x_{n}^{M}]$. Further, let us stack all responses in one vector $\\boldsymbol{t}=[t_{1}, \\dots, t_{N}]^{T}$, all inputs in a single matrix $\\boldsymbol{X}=[\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\dots, \\boldsymbol{x}_{N}]^{T}$. Then we get for the whole data set\n",
    "\\begin{equation}\n",
    "\\boldsymbol{t}=\\boldsymbol{X}\\boldsymbol{\\omega}+\\boldsymbol{\\epsilon},\n",
    "\\end{equation}\n",
    "where $\\boldsymbol{\\epsilon}=[\\epsilon_{1}, \\dots, \\epsilon_{N}]^{T}$. \n",
    "Assume that we know the true value of  $\\sigma^{2}$. \n",
    "\n",
    "1. Derive the posterior distribution of $\\boldsymbol{\\omega}$, i.e., $p(\\boldsymbol{\\omega}|\\boldsymbol{t}, \\boldsymbol{X}, \\sigma^{2})$.  \n",
    "Hint: Use the prior $p(\\boldsymbol{\\omega}|\\boldsymbol{\\mu_{0}}, \\boldsymbol{\\Sigma_{0}})=\\mathcal{N}(\\boldsymbol{\\mu_{0}}, \\boldsymbol{\\Sigma_{0}})$ and the fact that the posterior should be Gaussian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a40f2ecf7cbe678e37b0f4852475257d",
     "grade": true,
     "grade_id": "cell-d12dbe36ec039c0b",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "We use Bayes' rule to see which quantities must be estimated to find the posterior distribution over $\\mathbf{\\omega}$:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\mathbf{\\omega \\mid t, X}, \\sigma^2) = \\frac{p(\\mathbf{t} \\mid \\mathbf{X}, \\sigma^2, \\mathbf{\\omega}) p(\\mathbf{\\omega} \\mid \\mathbf{\\mu_0}, \\mathbf{\\Sigma_0})}{p(\\mathbf{t, X}, \\sigma^2)}\n",
    "\\end{equation}\n",
    "\n",
    "The two quantities we want are the prior and likelihood in the top section. The prior is given by the exercise hint.\n",
    "We will now obtain the likelihood, using the equation for $\\mathbf{t}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{t} &= \\mathbf{X\\omega + \\epsilon} \\\\\n",
    "&= \\mathbf{X \\omega} + N(\\epsilon \\mid 0, \\sigma^2) \\\\\n",
    "&= N(t \\mid X\\omega, \\sigma^2)\n",
    "\\end{align}\n",
    "\n",
    "We can write these distributions out:\n",
    "\\begin{align}\n",
    "p(\\mathbf{\\omega \\mid t, X}, \\sigma^2) & \\propto N(\\mathbf{t} \\mid \\mathbf{X\\omega}, \\sigma^2) N(\\mathbf{\\omega} \\mid \\mathbf{\\mu_0, \\Sigma_0}) \\\\\n",
    "&= \\left(\\frac{1}{2 \\pi \\sigma^2}\\right)^{N/2}e^{-\\frac{1}{2}(\\mathbf{X\\omega}-\\mathbf{t})^T\\sigma^{-2}(\\mathbf{X\\omega}-\\mathbf{t})} \\left( \\frac{1}{2 \\pi \\det{\\Sigma_0}}\\right)^{M/2}e^{-\\frac{1}{2}(\\mathbf{\\omega}-\\mathbf{\\mu_0})^T\\mathbf{\\Sigma_0}^{-1}({\\omega}-\\mathbf{\\mu_0})}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "And as usual, the marginal distribution is found by integrating over the prior and likelihood, giving this final formula for the posterior over $\\mathbf{\\omega}$:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\mathbf{\\omega \\mid t, X}, \\sigma^2) = \\frac{\\left(\\frac{1}{2 \\pi \\sigma^2}\\right)^{N/2}e^{-\\frac{1}{2}(\\mathbf{X\\omega}-\\mathbf{t})^T\\sigma^{-2}(\\mathbf{X\\omega}-\\mathbf{t})} \\left( \\frac{1}{2 \\pi \\det{\\Sigma_0}}\\right)^{M/2}e^{-\\frac{1}{2}(\\mathbf{\\omega}-\\mathbf{\\mu_0})^T\\mathbf{\\Sigma_0}^{-1}({\\omega}-\\mathbf{\\mu_0})}}{\\int \\left(\\frac{1}{2 \\pi \\sigma^2}\\right)^{N/2}e^{-\\frac{1}{2}(\\mathbf{X\\omega}-\\mathbf{t})^T\\sigma^{-2}(\\mathbf{X\\omega}-\\mathbf{t})} \\left( \\frac{1}{2 \\pi \\det{\\Sigma_0}}\\right)^{M/2}e^{-\\frac{1}{2}(\\mathbf{\\omega}-\\mathbf{\\mu_0})^T\\mathbf{\\Sigma_0}^{-1}({\\omega}-\\mathbf{\\mu_0})} \\mathrm{d} \\mathbf{\\omega}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2257e18d2051580aaa04605a7de4624",
     "grade": false,
     "grade_id": "cell-b7f2ed5b0213c674",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "2. Take the first order polynomial, the inputs are $\\boldsymbol{x_{n}}=[1, x_{n}]^{T}$. Let $\\boldsymbol{\\mu_{0}}=[0,0,\\dots,0]^{T}$. Then the posterior mean for the linear Gaussian model is\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\mu_{\\omega}}=(\\boldsymbol{X}^{T}\\boldsymbol{X}+ \\sigma^2 \\boldsymbol{\\Sigma_{0}^{-1}})^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}.\n",
    "\\label{eq:MAP} \\tag{1}\n",
    "\\end{equation}\n",
    "Recall also the regularized least squares solution:\n",
    "\\begin{equation}\n",
    "\\hat{\\boldsymbol{\\omega}}=(\\boldsymbol{X}^{T}\\boldsymbol{X}+N\\lambda\\boldsymbol{I})^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}.\n",
    "\\label{eq:MLE} \\tag{2}\n",
    "\\end{equation}\n",
    "Find $\\boldsymbol{\\Sigma_{0}}$ that makes Equation \\eqref{eq:MAP} and Equation \\eqref{eq:MLE} identical. Reflect on the similarity between MAP solution and regularized least squares. Comment on what it implies for the effect of the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "912de86d114accc7d731bcc56dbe5694",
     "grade": true,
     "grade_id": "cell-cb4a19df380490ad",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "In the equations $\\boldsymbol{\\mu_{\\omega}}=(\\boldsymbol{X}^{T}\\boldsymbol{X}+ \\sigma^2 \\boldsymbol{\\Sigma_{0}^{-1}})^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}$ and $\\hat{\\boldsymbol{\\omega}}=(\\boldsymbol{X}^{T}\\boldsymbol{X}+N\\lambda\\boldsymbol{I})^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}$, we can start by isolating the sections concerning $Sigma_0$, and set them equal to each other:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma^2\\Sigma_0^{-1} = N\\lambda \\boldsymbol{I}\n",
    "\\end{equation}\n",
    "\n",
    "From here, it's algebra:\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma^2\\Sigma_0^{-1} &= N\\lambda \\boldsymbol{I} \\\\\n",
    "\\sigma^2 &= N\\lambda \\boldsymbol{I} \\Sigma_0 \\\\\n",
    "\\frac{\\sigma^2}{N \\lambda} &= \\boldsymbol{I} \\Sigma_0 \\\\\n",
    "\\boldsymbol{I}^{-1} \\frac{\\sigma^2}{N \\lambda}&= \\Sigma_0 \\\\\n",
    "\\Sigma_0 &= \\boldsymbol{I} \\frac{\\sigma^2}{N \\lambda}\n",
    "\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "Let's consider what happens as the prior grows smaller. That is, consider $\\Sigma_0 = \\alpha \\Sigma_p$, as $\\alpha \\rightarrow 0$. This would mean that the effect of the prior also goes to zero (and same for $\\sigma^2$, the observation noise). Then, we would land on the a olution that looks very much like the Maximum Likelihood solution, $(X^TX)^{-1}X^Tt$eq. (3.15) in Bishop. However, let us stay for now on MAP and regularization. The effect of the prior covariance seems therefore to be considered analogous to that of the regularization constant; if we choose our $\\Sigma_0$ to be inversely proportional to our number of data points, as well as some regularizing factor $\\lambda$, then we are doing the same as we would in (quadratic) regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af076fd3bdffcdecc637a5a147e4afa6",
     "grade": false,
     "grade_id": "cell-f5c34c7115505339",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "3. Consider the polynomial function\n",
    "\\begin{equation}\n",
    "f(x) = 5x^{3} - x^{2} +x\n",
    "\\end{equation}\n",
    "which we will use to generate some training data. First define the function $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd447e5d584f85998c7474ba69e63f9b",
     "grade": false,
     "grade_id": "cell-ece70abe254c227c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"\n",
    "    Define the polynomial function f(x).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return 5*x**3 - x**2 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "485a90b1c2171bb148fb0af4b2580b71",
     "grade": true,
     "grade_id": "cell-5db410b0084695b0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the polynomial function f(x).\n",
    "\"\"\"\n",
    "assert f(0) == 0\n",
    "assert f(1) == 5\n",
    "assert f(-1) == -7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "205d6a978731ba6a481a9304f96de11d",
     "grade": false,
     "grade_id": "cell-6747240bfdc2c9d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Generate 40 random input points uniformly distributed on the interval $[-5, 5]$. Apply the function $f$ to the input data and then add Gaussian noise with mean zero and variance $\\sigma^2 = 150$ to obtain the target values ($\\boldsymbol{t}$). Plot the generated data on top of the true function $f(x)$ over the interval $[-5,5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e8b026b5772bba8676e93a59314d2b1",
     "grade": true,
     "grade_id": "cell-98a8f3ba37e9002f",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate 40 (X, t) pairs as described above and plot them (for comparison) on top of the function f(x).\n",
    "\n",
    "Variable names\n",
    "----------\n",
    "X : Nx1 array\n",
    "    The array containing the random data points.\n",
    "N : integer\n",
    "    The number of data points.\n",
    "t : Nx1 array\n",
    "    The array containing the random data points with Gaussian noise.\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "# 40 random input points:\n",
    "xs = np.atleast_2d(np.random.randint(-5, 5, 40))\n",
    "\n",
    "# apply the function and add noise\n",
    "var = 150\n",
    "ts = f(xs) + np.random.normal(0, np.sqrt(var), 40)\n",
    "\n",
    "axis = np.linspace(-5, 5, 500)\n",
    "plt.plot(axis, f(axis), label=\"True function\")\n",
    "plt.scatter(xs, ts, label=\"samples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdbe05d402e69d2191c79b32aaa50304",
     "grade": false,
     "grade_id": "cell-d600bad86391b6f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "4. Compute the marginal likelihood on the data generated above for the polynomial models from first to seventh order. Make a plot of the marginal likelihood for these models (polynomial order on the x-axis and marginal likelihood value on the y-axis). Use a Gaussian prior on $\\boldsymbol{\\omega}$ with **zero mean** ($\\boldsymbol{\\mu_0} = \\boldsymbol{0}$) and a **diagonal covariance matrix** ($\\boldsymbol{\\Sigma_0} = \\sigma_0^2 \\boldsymbol{I}$), and set the prior covariance hyperparameter $\\sigma_0^2$ (initially) to one. \n",
    "\n",
    "_Hint:_ \n",
    "The marginal likelihood (also known as the model evidence) for our Gaussian model is defined as $p(\\boldsymbol{t}|\\boldsymbol{X}, \\boldsymbol{\\mu_{0}}, \\boldsymbol{\\Sigma_{0}})$. The data matrix $\\boldsymbol{X}$ is defined at the beginning of the exercise. Note that this matrix is _order dependent_ and is different from the array of data points $\\{x_1, x_2, ..., x_{40}\\}$. Using Gaussian distributions as before we can compute\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{t}|\\boldsymbol{X}, \\boldsymbol{\\mu_{0}}, \\boldsymbol{\\Sigma_{0}})= \\mathcal{N}(\\boldsymbol{t}; \\boldsymbol{X}\\boldsymbol{\\mu_{0}}, \\sigma^{2}\\boldsymbol{I}_{N}+\\boldsymbol{X}\\boldsymbol{\\Sigma_{0}}\\boldsymbol{X}^{T}).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcbbab49c93464ab5564af67004be729",
     "grade": false,
     "grade_id": "cell-cadd5890106dd435",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_marginal_likelihood(X, N, t, sigma_0=1, sigma_n=1):\n",
    "    \"\"\"\n",
    "    Calculate the log marginal likelihood for the polynomial models from first to seventh order.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Nx1 array\n",
    "        The array containing the random data points.\n",
    "    N : numeric\n",
    "        The number of data points.\n",
    "    t : Nx1 array\n",
    "        The array containing the random data points with Gaussian noise.\n",
    "    sigma_0: numeric\n",
    "        Prior covariance hyperparameter.\n",
    "    sigma_n: numeric\n",
    "        Noise covariance hyperparameter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The list contains seven log marginal likelihood values corresponding to the different polynomial orders \n",
    "        (from first to seventh order).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    orders = np.arange(1, 8)\n",
    "    margs  = []\n",
    "\n",
    "    # NOTE: for a Bayesian linear regression model of the form y = X@Theta + epsilon, where epsilon represents the \"sampling\" noise of our data, we need a parameter for that sampling noise. In the equation above, that is, as far as I can tell, the $sigma^2$ (with NO sub-script). However, no guidance was given for this. Therefore, I set it to equal 1. This is obviously ludicrious wrt our generated data, where the actual covariance was sqrt(150), but... it would work for standardized data.\n",
    "    sigma_n = 1\n",
    "\n",
    "    def lml(t, x, M, m0=0, sig_0=sigma_0):\n",
    "        mu0 = np.full(M+1, m0)\n",
    "        Sig_0 = np.eye(M+1)*np.sqrt(sig_0)\n",
    "        mean = x@mu0\n",
    "        cov = sigma_n*np.eye(N)+x@Sig_0@x.T\n",
    "\n",
    "        # Implementation to get lognormal distribution: \n",
    "        sign, log_det_sigma_0 = np.linalg.slogdet(cov)\n",
    "        diff = t - mean\n",
    "\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "\n",
    "        ll = -0.5 * (diff@cov_inv@diff.T + N * (np.log(2*np.pi) + log_det_sigma_0))\n",
    "\n",
    "        return ll\n",
    "    \n",
    "    \n",
    "    for i, M in enumerate(orders):\n",
    "        # construct data matrix\n",
    "        x = np.zeros((N, M+1))\n",
    "        for j in range(M+1):\n",
    "            x[:,j] = X**j\n",
    "\n",
    "        # get log marginal likelihoods\n",
    "        margs.append(lml(t, x, M))\n",
    "\n",
    "    return margs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd8b3c94cc0fda8b7cb64e7d4a293f60",
     "grade": true,
     "grade_id": "cell-d78cc77a3b106231",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTest for log_marginal_likelihood.\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test for log_marginal_likelihood.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "556a2ec64e11e892fefab07aab65cfac",
     "grade": false,
     "grade_id": "cell-1f442d34ca5e329e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now plot the results with the help of `log_marginal_likelihood`. You can use `matplotlib.pyplot.bar` for making the bar plot.  \n",
    "\n",
    "_Hint_: You might want to normalize by computing the difference between the log marginal likelihood values and their maximum, and by then taking the exponent of these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa1c2a606aff57a09e9ccd7cfccd1248",
     "grade": true,
     "grade_id": "cell-8ecce257dda193fb",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the marginal likelihood values for different polynomial orders.\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e226b2513c6f81856187f2f883afa10e",
     "grade": false,
     "grade_id": "cell-9df069813f400546",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Based on the plot, which model would you choose according to the marginal likelihood?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "885d2a6cd882acee5263ad4e39d8d096",
     "grade": true,
     "grade_id": "cell-3f01a1d2ee023123",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57ef369b4cb2c53907b5a2869407318a",
     "grade": false,
     "grade_id": "cell-6a4a4988e7332fb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "5. How would the prior affect the choice of polynomial using marginal likelihood? Let $\\boldsymbol{\\Sigma_{0}}=\\sigma_{0}^{2}\\boldsymbol{I}$ as before and vary $\\sigma_{0}^{2}$. What happens when you increase and decrease $\\sigma_{0}^{2}$? Plot the marginal likelihood for each polynomial order from 1 to 7, for the following hyperparameter values: $\\sigma_{0}^{2}=0.1$ , $\\sigma_{0}^{2}=0.3$, $\\sigma_{0}^{2}=0.4$, $\\sigma_{0}^{2}=0.7$, $\\sigma_{0}^{2}=1.3$, $\\sigma_{0}^{2}=1.4$, $\\sigma_{0}^{2}=1.7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c58084ddc2f8bcbd85637610976c326f",
     "grade": true,
     "grade_id": "cell-5a8f27b42908767d",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the marginal likelihood values for different polynomial orders. We now consider different values for sigma_0.\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "\n",
    "hypersigmas = [0.1, 0.3, 0.4, 0.7, 1.3, 1.4, 1.7]\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb47a4c8256b3535da9ade0b5702f1ac",
     "grade": false,
     "grade_id": "cell-9278e618c146a07f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Comment on the effect of changing $\\sigma_{0}^{2}$. What does it imply, in general, for such a modeling choice (i.e. for the _Bayesian_ way of estimation for the polynomial regression)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a182b96796132e4977b8bedcb7ef214",
     "grade": true,
     "grade_id": "cell-e2e8c5e272656373",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
